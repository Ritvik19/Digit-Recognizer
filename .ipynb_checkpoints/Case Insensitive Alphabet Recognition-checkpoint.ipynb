{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:19:21.814520Z",
     "start_time": "2019-12-27T10:19:07.155801Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:19:21.825492Z",
     "start_time": "2019-12-27T10:19:21.817512Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:19:47.053765Z",
     "start_time": "2019-12-27T10:19:21.832474Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_flat = pd.read_csv('../[Data] HandWriting-Recognition/emnist/emnist-letters-train.csv', header=None).iloc[:, 1: ].values\n",
    "X_test_flat =  pd.read_csv('../[Data] HandWriting-Recognition/emnist/emnist-letters-test.csv', header=None).iloc[:, 1:].values\n",
    "\n",
    "y_train = pd.read_csv('../[Data] HandWriting-Recognition/emnist/emnist-letters-train.csv', header=None)[0].values\n",
    "y_test = pd.read_csv('../[Data] HandWriting-Recognition/emnist/emnist-letters-test.csv', header=None)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:19:47.075708Z",
     "start_time": "2019-12-27T10:19:47.057756Z"
    },
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "88800\n",
      "(88800, 784)\n",
      "(88800,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Set')\n",
    "print(len(y_train))\n",
    "print(X_train_flat.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:19:47.514750Z",
     "start_time": "2019-12-27T10:19:47.085682Z"
    },
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set\n",
      "14800\n",
      "(14800, 784)\n",
      "(14800,)\n"
     ]
    }
   ],
   "source": [
    "print('Testing Set')\n",
    "print(len(y_test))\n",
    "print(X_test_flat.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:19:51.560673Z",
     "start_time": "2019-12-27T10:19:47.522696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1aa84121198>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train_flat[1].reshape(28,28),cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:20:41.980207Z",
     "start_time": "2019-12-27T10:19:51.564665Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:20:41.999158Z",
     "start_time": "2019-12-27T10:20:41.984199Z"
    },
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88800, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train_flat.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test_flat.reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:20:42.602544Z",
     "start_time": "2019-12-27T10:20:42.006139Z"
    },
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:20:43.043381Z",
     "start_time": "2019-12-27T10:20:42.605537Z"
    },
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "X_train_flat = X_train_flat.astype('float32')\n",
    "X_test_flat = X_test_flat.astype('float32')\n",
    "X_train_flat /= 255.0\n",
    "X_test_flat /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:20:43.482177Z",
     "start_time": "2019-12-27T10:20:43.045361Z"
    }
   },
   "outputs": [],
   "source": [
    "X_all = np.concatenate((X_train, X_test))\n",
    "y_all = np.concatenate((y_train,  y_test))-1\n",
    "X_all_flat = np.concatenate((X_train_flat, X_test_flat))\n",
    "y_all_cat = to_categorical(y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:20:57.546338Z",
     "start_time": "2019-12-27T10:20:43.484083Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:20:57.566200Z",
     "start_time": "2019-12-27T10:20:57.553237Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:20:59.537530Z",
     "start_time": "2019-12-27T10:20:57.583155Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:32:24.802887Z",
     "start_time": "2019-12-27T10:20:59.540523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[453   6   4  24  26  18  21  32   1   1  12   1   9  40  18  10  33   7\n",
      "    2   4  27   0   8  12   4  27]\n",
      " [  6 598   0  30  16   0  30  35   7   5   3  11   4   4   7   3   4   1\n",
      "    5   1   7   0   1   3   3  16]\n",
      " [  6   3 643   1  39   2   9   0   3   3  10   7   0   3  24   6   6  13\n",
      "    0   5  10   2   1   0   0   4]\n",
      " [ 15  54   3 473   5   1   6  25   4  18  10  12   3   6  73  13  14   0\n",
      "    3   3  20   9   5   1   3  21]\n",
      " [ 22  14  52   0 598   8   7   1   0   1  20   2   1   4   9   2   6  19\n",
      "    8  12   3   0   0   3   1   7]\n",
      " [  3   5   2   3   5 592   3   4   5   5   3   6   2   3   0  60  10  19\n",
      "    5  38   0   2   0   6  17   2]\n",
      " [ 31  35  30   3  14  19 343  11   1  31   3   1   3   5  12  14 140   4\n",
      "   45  19   7   1   8   2  15   3]\n",
      " [ 14  13   2  19   2   6   4 545  15   3  35  22  20  55   0   1   1   1\n",
      "    1   0   6  12  10   8   2   3]\n",
      " [  2   2   1   3   1   5   1   2 498  21   2 181   1   0   0   4   9   3\n",
      "    9  10   2   3   0  19   7  14]\n",
      " [  3  10   3  38   1   0   9   4  12 613   0  23   0   1   2   3   9   0\n",
      "   25  11   3   1   0   4  12  13]\n",
      " [ 13  23  14   5  11   4   1  54  14   0 530  17   5   3   0   2   2  32\n",
      "    1   3   9  16   3  25   6   7]\n",
      " [  0   8  12   3   0   4   0   1 199   5  12 451   0   1   0   6   1   2\n",
      "    2   8  22  11   1  17  25   9]\n",
      " [  7   1   0   2   0   2   0   8   0   0   2   0 715  38   1   5   4   1\n",
      "    0   3   2   1   2   1   5   0]\n",
      " [ 38   4   0   8   2   1   1  31   0   3  30   0  51 508   4   5   1   6\n",
      "    0   4  15  31  48   6   1   2]\n",
      " [ 12   4   7  17   0   1  12   1   0   2   0   0   3   8 708   2  10   7\n",
      "    0   0   4   0   1   0   0   1]\n",
      " [  3   0   2   1   6  14   5   1   0   0   1   1   0   5   5 683   9  21\n",
      "    0  19   1   0   0   3  19   1]\n",
      " [ 42  11   5  13   7  23  77   2   4   7   8   1   1   4  12  20 485   2\n",
      "    6  30   7   0   5   5  16   7]\n",
      " [ 39   5  16   2  19  25   2   8   6   1  42   2   8   6   2  16  21 484\n",
      "    1  38   0   7   3  17  20  10]\n",
      " [  9   3   2   1   2   2   9   0   3  24   1   2   0   2   2   0   4   2\n",
      "  325   1   1   1   0   1   1   2]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.57      0.60       800\n",
      "           2       0.75      0.75      0.75       800\n",
      "           3       0.81      0.80      0.80       800\n",
      "           4       0.73      0.59      0.65       800\n",
      "           5       0.79      0.75      0.77       800\n",
      "           6       0.81      0.74      0.78       800\n",
      "           7       0.64      0.43      0.51       800\n",
      "           8       0.71      0.68      0.70       800\n",
      "           9       0.65      0.62      0.63       800\n",
      "          10       0.83      0.77      0.79       800\n",
      "          11       0.73      0.66      0.70       800\n",
      "          12       0.61      0.56      0.59       800\n",
      "          13       0.87      0.89      0.88       800\n",
      "          14       0.73      0.64      0.68       800\n",
      "          15       0.81      0.89      0.84       800\n",
      "          16       0.80      0.85      0.83       800\n",
      "          17       0.63      0.61      0.62       800\n",
      "          18       0.78      0.60      0.68       800\n",
      "          19       0.74      0.81      0.78       400\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     14800\n",
      "   macro avg       0.54      0.51      0.52     14800\n",
      "weighted avg       0.74      0.69      0.71     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_flat, y_train)\n",
    "pred = model.predict(X_test_flat)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:32:30.917195Z",
     "start_time": "2019-12-27T10:32:24.806875Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(X_all_flat, y_all)\n",
    "pickle.dump(model, open('E:/Models/Case-Insesitive-Alphabet-Recognition/LogisticRegression.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:32:31.720682Z",
     "start_time": "2019-12-27T10:32:30.920158Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:32:44.667751Z",
     "start_time": "2019-12-27T10:32:31.725585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[660   4   2   9   5   5  18  14   1   1   4   0   6  15  17   3  24   4\n",
      "    0   0   1   0   1   1   0   5]\n",
      " [ 12 689   2  16   6   8  15  12   1   1   1   5   1   3   4   3   1   2\n",
      "    4   3   1   0   0   0   0  10]\n",
      " [ 15   3 720   2  32   3   1   0   0   0   1   6   0   0   3   3   1   5\n",
      "    0   0   4   0   0   1   0   0]\n",
      " [ 15  41   0 655   1   3   3   3   2   4   5   0   1   6  40   4   1   0\n",
      "    1   3   4   0   2   0   0   6]\n",
      " [ 13  13  37   1 687   6   7   1   1   0   5   2   0   1   3   4   2   6\n",
      "    2   4   0   0   0   1   0   4]\n",
      " [  3   2   2   2   5 684   6   2   5   3   3   2   0   0   0  45   3   2\n",
      "    1  28   0   0   0   1   1   0]\n",
      " [ 46  31  15   6  11  25 500   1   2  11   4   2   2   1   6   4 104   1\n",
      "   12   1   1   2   2   0   6   4]\n",
      " [ 23  21   0  10   1   3   4 642   3   1  15   9  12  32   1   0   1   0\n",
      "    0   0   7   1   4   7   1   2]\n",
      " [  2   3   0   3   1   4   3   2 580  14   1 161   1   0   0   2   1   1\n",
      "    1   3   1   1   0   1   3  11]\n",
      " [  4   4   0  17   0   6   7   0  23 689   0   9   0   0   0   0   2   0\n",
      "    9  19   2   2   0   1   3   3]\n",
      " [ 10   7  10   3   2   6   2  31   5   2 667   4   2   1   0   4   1   6\n",
      "    0   6   5   4   2  17   0   3]\n",
      " [  0   7  14   4   2   5   0   8 208   2   2 538   0   1   1   2   1   0\n",
      "    1   0   0   0   0   1   2   1]\n",
      " [ 14   2   0   0   1   1   0  10   0   0   5   0 738  14   0   2   2   0\n",
      "    0   1   4   1   5   0   0   0]\n",
      " [ 32   3   1  11   1   2   2  35   0   2  13   0  32 633   1   0   1   3\n",
      "    0   0   5   3  19   0   0   1]\n",
      " [  9   3   4  28   3   1   2   0   0   0   0   1   2   2 739   1   1   0\n",
      "    1   0   1   1   1   0   0   0]\n",
      " [  2   1   0   5   4  34   3   3   2   1   0   2   0   3   1 717   7   5\n",
      "    0   7   0   0   0   1   1   1]\n",
      " [ 47  13   6   8   8  23 102   5   7   5   3   3   1   6  18  11 497   4\n",
      "    4   9   9   0   3   2   4   2]\n",
      " [ 37   2   3   2  14  15   2   0   1   0  24   2   1   3   1  11   7 640\n",
      "    0   7   1   9   1   9   6   2]\n",
      " [  5   2   1   2   1   1  16   1   1  17   0   0   1   0   3   0   0   1\n",
      "  347   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.82      0.75       800\n",
      "           2       0.81      0.86      0.83       800\n",
      "           3       0.88      0.90      0.89       800\n",
      "           4       0.84      0.82      0.83       800\n",
      "           5       0.88      0.86      0.87       800\n",
      "           6       0.82      0.85      0.84       800\n",
      "           7       0.72      0.62      0.67       800\n",
      "           8       0.83      0.80      0.82       800\n",
      "           9       0.69      0.72      0.71       800\n",
      "          10       0.92      0.86      0.89       800\n",
      "          11       0.89      0.83      0.86       800\n",
      "          12       0.72      0.67      0.70       800\n",
      "          13       0.92      0.92      0.92       800\n",
      "          14       0.88      0.79      0.83       800\n",
      "          15       0.88      0.92      0.90       800\n",
      "          16       0.88      0.90      0.89       800\n",
      "          17       0.76      0.62      0.68       800\n",
      "          18       0.94      0.80      0.86       800\n",
      "          19       0.91      0.87      0.89       400\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     14800\n",
      "   macro avg       0.61      0.59      0.60     14800\n",
      "weighted avg       0.83      0.81      0.82     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_flat, y_train)\n",
    "pred = model.predict(X_test_flat)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:32:50.449523Z",
     "start_time": "2019-12-27T10:32:44.671741Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(X_all_flat, y_all)\n",
    "pickle.dump(model, open('E:/Models/Case-Insesitive-Alphabet-Recognition/RandomForestClassifier.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:32:50.480478Z",
     "start_time": "2019-12-27T10:32:50.451529Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:32:52.102676Z",
     "start_time": "2019-12-27T10:32:50.484432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[339   7   3  70  14   9  22  62   2   2  10   3  43  65  37   4  30   3\n",
      "    1   1  18   1  38   6   4   6]\n",
      " [ 10 516   1  60  12   3  38  25  33  14   1  15   1  12  12   2   9   1\n",
      "    2   2   6   0   2   2   4  17]\n",
      " [ 19   5 509   9  78   4  26   0   1   0   6   8   2   6  69   7   6   9\n",
      "    0   9   9   1  14   0   0   3]\n",
      " [ 16  92   3 397   3   3  18   9  21  20   4  31   2   5  76   9   5   0\n",
      "    0   0  15  38   8   2   6  17]\n",
      " [ 78  27  97   6 452  21  14   0   1   0   5   2   3   8   8   8   9  25\n",
      "    7  13   2   0   8   2   0   4]\n",
      " [  7   4   2   2   2 434   2   4  48   9   1  10   6   4   0 144  21  50\n",
      "    2  32   0   6   0   4   5   1]\n",
      " [ 44  45  17  23   6  30 290  11  21  55   2  11   3   4   9  10 116   2\n",
      "   37  21   9   1  11   0  17   5]\n",
      " [ 22  15   1  36   0   9   1 442  56   6  28  17  16  70   0   5   0   3\n",
      "    0   1  26  10  15  13   5   3]\n",
      " [  5   4   0   0   0   1   0   0 630  33   3  30   1   0   0   0   0   3\n",
      "    4   4   3   4   0  33  19  23]\n",
      " [  6  16   1 121   2  26   2   3  48 435   0   6   2   2   4   0   6  28\n",
      "   11  25  16  13   2   3   4  18]\n",
      " [ 12  12  10   8   8   7   1  72  14   1 463  17  16  26   0   5   1  14\n",
      "    0  28   5  13  16  35  10   6]\n",
      " [  2  45  42   4   0   1   1   3 481   1  15  53   0   2   2   2   0   2\n",
      "    1   3  27  13   9  33  43  15]\n",
      " [  8   0   0   0   0   1   0   1   0   0   1   0 687  84   1   1   1   0\n",
      "    0   0   6   1   6   0   0   2]\n",
      " [ 36   2   0  12   1   6   0  38   1   0  11   0 101 427  10   1   1   0\n",
      "    0   2  27  29  91   3   1   0]\n",
      " [ 33   8  29  21   0   1  10   3   2   0   0   0  10  14 643   1   7   2\n",
      "    0  10   5   0   0   1   0   0]\n",
      " [  1   0   0   0   0  13   0   1  16   1   0   1   2  26   5 616   9  29\n",
      "    0  57   1   0   1   3  17   1]\n",
      " [ 43  16   3   7   4  27  68   6  44   3   7  18   3   4  25  13 395   2\n",
      "    9  43  22   0   6   2  25   5]\n",
      " [ 42   0   5   6  11  27   0  15   6   0  53   5  25  24   1  45  21 407\n",
      "    1  54   2  14   2  14  18   2]\n",
      " [ 18  16   0   3   5   6  10   2   6  41   0   3   1   1   6   0   4   2\n",
      "  263   1   2   0   1   5   0   4]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.42      0.44       800\n",
      "           2       0.62      0.65      0.63       800\n",
      "           3       0.70      0.64      0.67       800\n",
      "           4       0.51      0.50      0.50       800\n",
      "           5       0.76      0.56      0.65       800\n",
      "           6       0.69      0.54      0.61       800\n",
      "           7       0.58      0.36      0.45       800\n",
      "           8       0.63      0.55      0.59       800\n",
      "           9       0.44      0.79      0.56       800\n",
      "          10       0.70      0.54      0.61       800\n",
      "          11       0.76      0.58      0.66       800\n",
      "          12       0.23      0.07      0.10       800\n",
      "          13       0.74      0.86      0.80       800\n",
      "          14       0.54      0.53      0.54       800\n",
      "          15       0.71      0.80      0.75       800\n",
      "          16       0.71      0.77      0.74       800\n",
      "          17       0.62      0.49      0.55       800\n",
      "          18       0.70      0.51      0.59       800\n",
      "          19       0.78      0.66      0.71       400\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.57      0.57      0.57     14800\n",
      "   macro avg       0.46      0.42      0.43     14800\n",
      "weighted avg       0.62      0.57      0.58     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_flat, y_train)\n",
    "pred = model.predict(X_test_flat)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:32:58.130072Z",
     "start_time": "2019-12-27T10:32:52.105670Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB(X_all_flat, y_all)\n",
    "pickle.dump(model, open('E:/Models/Case-Insesitive-Alphabet-Recognition/MultinomialNB.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:32:58.213521Z",
     "start_time": "2019-12-27T10:32:58.207565Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T10:46:39.538066Z",
     "start_time": "2019-12-27T10:32:58.219536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Ritvik\\Anaconda3\\envs\\datascience\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Users\\Ritvik\\Anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                32800     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 26)                858       \n",
      "=================================================================\n",
      "Total params: 837,498\n",
      "Trainable params: 837,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From D:\\Users\\Ritvik\\Anaconda3\\envs\\datascience\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 72520 samples, validate on 31080 samples\n",
      "Epoch 1/50\n",
      "72520/72520 [==============================] - 41s 562us/step - loss: 0.9809 - acc: 0.7053 - val_loss: 0.5251 - val_acc: 0.8341\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.98089, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 2/50\n",
      "72520/72520 [==============================] - 38s 524us/step - loss: 0.5609 - acc: 0.8244 - val_loss: 0.4290 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00002: loss improved from 0.98089 to 0.56090, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 3/50\n",
      "72520/72520 [==============================] - 36s 499us/step - loss: 0.4589 - acc: 0.8536 - val_loss: 0.4001 - val_acc: 0.8753\n",
      "\n",
      "Epoch 00003: loss improved from 0.56090 to 0.45886, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 4/50\n",
      "72520/72520 [==============================] - 34s 465us/step - loss: 0.4140 - acc: 0.8656 - val_loss: 0.3751 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00004: loss improved from 0.45886 to 0.41396, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 5/50\n",
      "72520/72520 [==============================] - 34s 464us/step - loss: 0.3777 - acc: 0.8760 - val_loss: 0.3579 - val_acc: 0.8856\n",
      "\n",
      "Epoch 00005: loss improved from 0.41396 to 0.37768, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 6/50\n",
      "72520/72520 [==============================] - 34s 470us/step - loss: 0.3495 - acc: 0.8844 - val_loss: 0.3513 - val_acc: 0.8918\n",
      "\n",
      "Epoch 00006: loss improved from 0.37768 to 0.34945, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 7/50\n",
      "72520/72520 [==============================] - 34s 462us/step - loss: 0.3300 - acc: 0.8905 - val_loss: 0.3495 - val_acc: 0.8935\n",
      "\n",
      "Epoch 00007: loss improved from 0.34945 to 0.33001, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 8/50\n",
      "72520/72520 [==============================] - 34s 463us/step - loss: 0.3125 - acc: 0.8943 - val_loss: 0.3510 - val_acc: 0.8926\n",
      "\n",
      "Epoch 00008: loss improved from 0.33001 to 0.31248, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 9/50\n",
      "72520/72520 [==============================] - 34s 475us/step - loss: 0.2968 - acc: 0.8982 - val_loss: 0.3548 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00009: loss improved from 0.31248 to 0.29684, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 10/50\n",
      "72520/72520 [==============================] - 34s 466us/step - loss: 0.2882 - acc: 0.9025 - val_loss: 0.3551 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00010: loss improved from 0.29684 to 0.28823, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 11/50\n",
      "72520/72520 [==============================] - 34s 463us/step - loss: 0.2740 - acc: 0.9056 - val_loss: 0.3749 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00011: loss improved from 0.28823 to 0.27402, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 12/50\n",
      "72520/72520 [==============================] - 34s 463us/step - loss: 0.2638 - acc: 0.9074 - val_loss: 0.3616 - val_acc: 0.8977\n",
      "\n",
      "Epoch 00012: loss improved from 0.27402 to 0.26376, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 13/50\n",
      "72520/72520 [==============================] - 34s 469us/step - loss: 0.2563 - acc: 0.9112 - val_loss: 0.3576 - val_acc: 0.9001\n",
      "\n",
      "Epoch 00013: loss improved from 0.26376 to 0.25631, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 14/50\n",
      "72520/72520 [==============================] - 34s 471us/step - loss: 0.2468 - acc: 0.9142 - val_loss: 0.3617 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00014: loss improved from 0.25631 to 0.24676, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 15/50\n",
      "72520/72520 [==============================] - 35s 480us/step - loss: 0.2438 - acc: 0.9144 - val_loss: 0.3584 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00015: loss improved from 0.24676 to 0.24380, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 16/50\n",
      "72520/72520 [==============================] - 36s 500us/step - loss: 0.2375 - acc: 0.9167 - val_loss: 0.3767 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00016: loss improved from 0.24380 to 0.23746, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 17/50\n",
      "72520/72520 [==============================] - 35s 481us/step - loss: 0.2270 - acc: 0.9190 - val_loss: 0.3692 - val_acc: 0.9013\n",
      "\n",
      "Epoch 00017: loss improved from 0.23746 to 0.22702, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 18/50\n",
      "72520/72520 [==============================] - 36s 491us/step - loss: 0.2223 - acc: 0.9217 - val_loss: 0.3643 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00018: loss improved from 0.22702 to 0.22234, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 19/50\n",
      "72520/72520 [==============================] - 39s 532us/step - loss: 0.2196 - acc: 0.9217 - val_loss: 0.3811 - val_acc: 0.8977\n",
      "\n",
      "Epoch 00019: loss improved from 0.22234 to 0.21958, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 20/50\n",
      "72520/72520 [==============================] - 37s 511us/step - loss: 0.2121 - acc: 0.9244 - val_loss: 0.3854 - val_acc: 0.8981\n",
      "\n",
      "Epoch 00020: loss improved from 0.21958 to 0.21207, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 21/50\n",
      "72520/72520 [==============================] - 34s 470us/step - loss: 0.2104 - acc: 0.9248 - val_loss: 0.3929 - val_acc: 0.8977\n",
      "\n",
      "Epoch 00021: loss improved from 0.21207 to 0.21045, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 22/50\n",
      "72520/72520 [==============================] - 35s 476us/step - loss: 0.2070 - acc: 0.9253 - val_loss: 0.4033 - val_acc: 0.8961\n",
      "\n",
      "Epoch 00022: loss improved from 0.21045 to 0.20696, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\n",
      "Epoch 23/50\n",
      "72520/72520 [==============================] - 36s 497us/step - loss: 0.2074 - acc: 0.9263 - val_loss: 0.3895 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.20696\n",
      "Epoch 00023: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aac8f31668>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1)\n",
    "filepath = \"E:/Models/Case-Insesitive-Alphabet-Recognition/ANN.h5\"\n",
    "ckpt = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "def build_network():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024,input_dim=784, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(26, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = build_network()\n",
    "\n",
    "model.fit(X_all_flat, y_all_cat, validation_split=0.3, epochs=50, callbacks=[es, ckpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T11:39:18.132984Z",
     "start_time": "2019-12-27T10:46:39.541056Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               2769024   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 26)                3354      \n",
      "=================================================================\n",
      "Total params: 2,772,698\n",
      "Trainable params: 2,772,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 72520 samples, validate on 31080 samples\n",
      "Epoch 1/50\n",
      "72520/72520 [==============================] - 141s 2ms/step - loss: 0.7258 - acc: 0.7770 - val_loss: 0.3914 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.72584, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 2/50\n",
      "72520/72520 [==============================] - 138s 2ms/step - loss: 0.3875 - acc: 0.8741 - val_loss: 0.3450 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00002: loss improved from 0.72584 to 0.38745, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 3/50\n",
      "72520/72520 [==============================] - 139s 2ms/step - loss: 0.3165 - acc: 0.8934 - val_loss: 0.3169 - val_acc: 0.8985\n",
      "\n",
      "Epoch 00003: loss improved from 0.38745 to 0.31652, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 4/50\n",
      "72520/72520 [==============================] - 146s 2ms/step - loss: 0.2747 - acc: 0.9062 - val_loss: 0.3069 - val_acc: 0.9013\n",
      "\n",
      "Epoch 00004: loss improved from 0.31652 to 0.27475, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 5/50\n",
      "72520/72520 [==============================] - 141s 2ms/step - loss: 0.2382 - acc: 0.9164 - val_loss: 0.3174 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00005: loss improved from 0.27475 to 0.23820, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 6/50\n",
      "72520/72520 [==============================] - 141s 2ms/step - loss: 0.2121 - acc: 0.9247 - val_loss: 0.3117 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00006: loss improved from 0.23820 to 0.21210, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 7/50\n",
      "72520/72520 [==============================] - 141s 2ms/step - loss: 0.1873 - acc: 0.9310 - val_loss: 0.3278 - val_acc: 0.9023\n",
      "\n",
      "Epoch 00007: loss improved from 0.21210 to 0.18734, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 8/50\n",
      "72520/72520 [==============================] - 148s 2ms/step - loss: 0.1677 - acc: 0.9384 - val_loss: 0.3303 - val_acc: 0.9044\n",
      "\n",
      "Epoch 00008: loss improved from 0.18734 to 0.16768, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 9/50\n",
      "72520/72520 [==============================] - 142s 2ms/step - loss: 0.1551 - acc: 0.9424 - val_loss: 0.3306 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00009: loss improved from 0.16768 to 0.15506, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 10/50\n",
      "72520/72520 [==============================] - 143s 2ms/step - loss: 0.1426 - acc: 0.9465 - val_loss: 0.3423 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00010: loss improved from 0.15506 to 0.14263, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 11/50\n",
      "72520/72520 [==============================] - 143s 2ms/step - loss: 0.1299 - acc: 0.9506 - val_loss: 0.3530 - val_acc: 0.9037- loss: \n",
      "\n",
      "Epoch 00011: loss improved from 0.14263 to 0.12991, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 12/50\n",
      "72520/72520 [==============================] - 148s 2ms/step - loss: 0.1252 - acc: 0.9518 - val_loss: 0.3663 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00012: loss improved from 0.12991 to 0.12524, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 13/50\n",
      "72520/72520 [==============================] - 141s 2ms/step - loss: 0.1147 - acc: 0.9559 - val_loss: 0.4005 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00013: loss improved from 0.12524 to 0.11471, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 14/50\n",
      "72520/72520 [==============================] - 143s 2ms/step - loss: 0.1071 - acc: 0.9585 - val_loss: 0.3906 - val_acc: 0.8979\n",
      "\n",
      "Epoch 00014: loss improved from 0.11471 to 0.10713, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 15/50\n",
      "72520/72520 [==============================] - 143s 2ms/step - loss: 0.1050 - acc: 0.9603 - val_loss: 0.4192 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00015: loss improved from 0.10713 to 0.10498, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 16/50\n",
      "72520/72520 [==============================] - 148s 2ms/step - loss: 0.1000 - acc: 0.9612 - val_loss: 0.4049 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00016: loss improved from 0.10498 to 0.10001, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 17/50\n",
      "72520/72520 [==============================] - 143s 2ms/step - loss: 0.0934 - acc: 0.9638 - val_loss: 0.4094 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00017: loss improved from 0.10001 to 0.09336, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 18/50\n",
      "72520/72520 [==============================] - 143s 2ms/step - loss: 0.0901 - acc: 0.9657 - val_loss: 0.4286 - val_acc: 0.9045\n",
      "\n",
      "Epoch 00018: loss improved from 0.09336 to 0.09014, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 19/50\n",
      "72520/72520 [==============================] - 143s 2ms/step - loss: 0.0891 - acc: 0.9662 - val_loss: 0.4178 - val_acc: 0.9044\n",
      "\n",
      "Epoch 00019: loss improved from 0.09014 to 0.08906, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 20/50\n",
      "72520/72520 [==============================] - 146s 2ms/step - loss: 0.0829 - acc: 0.9693 - val_loss: 0.4625 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00020: loss improved from 0.08906 to 0.08288, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 21/50\n",
      "72520/72520 [==============================] - 144s 2ms/step - loss: 0.0781 - acc: 0.9698 - val_loss: 0.4690 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00021: loss improved from 0.08288 to 0.07808, saving model to E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\n",
      "Epoch 22/50\n",
      "72520/72520 [==============================] - 143s 2ms/step - loss: 0.0809 - acc: 0.9696 - val_loss: 0.4620 - val_acc: 0.9033\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.07808\n",
      "Epoch 00022: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aac9f76ac8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1)\n",
    "filepath = \"E:/Models/Case-Insesitive-Alphabet-Recognition/CNN.h5\"\n",
    "ckpt = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "def cnn(image_size):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Conv2D(32, (3, 3), input_shape = (*image_size, 1), activation = 'relu'))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(Dense(units = 26, activation = 'softmax'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    classifier.summary()\n",
    "    return classifier\n",
    "\n",
    "\n",
    "model = cnn((28,28))\n",
    "\n",
    "model.fit(X_all, y_all_cat, validation_split=0.3, epochs=50, callbacks=[es, ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
